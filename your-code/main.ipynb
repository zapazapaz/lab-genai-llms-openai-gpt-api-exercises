{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB GenAI - LLMs - OpenAI GPT API Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a simple chatbot that can answer basic questions about a given topic (e.g., history, technology).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.61.0\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: https://github.com/openai/openai-python\n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: \n",
      "Location: C:\\Users\\igriz\\anaconda3\\Lib\\site-packages\n",
      "Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show openai\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Infinite loops call,  \\nself within the function's frame,  \\nechoes of the first.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key = )\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a haiku about recursion in programming.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Write a script that takes a long text input and summarizes it into a few sentences.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      " AI has transformed industries like healthcare, finance, and entertainment by using machine learning for tasks such as disease diagnosis, stock market prediction, and content personalization. Advances in natural language processing have enhanced chatbots and virtual assistants. However, ethical issues like bias and\n"
     ]
    }
   ],
   "source": [
    "api_key = \n",
    "def summarize_text(text, temperature=0.7, max_tokens=100, top_p=0.9, \n",
    "                   frequency_penalty=0.0, presence_penalty=0.0, logprobs=None):\n",
    "    \"\"\"\n",
    "    Summarizes a given text using OpenAI's GPT API.\n",
    "    \"\"\"\n",
    "    \n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI that summarizes text.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Summarize this text in a few sentences:\\n\\n{text}\"}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "        logprobs=logprobs  # This is optional; set to None if not needed\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Example long text input\n",
    "long_text = \"\"\"\n",
    "Artificial Intelligence (AI) has revolutionized various industries, including healthcare, finance, and entertainment. \n",
    "Machine learning algorithms are being used to diagnose diseases, predict stock market trends, and personalize content recommendations. \n",
    "With advancements in natural language processing, AI can now understand and generate human-like text, making chatbots and virtual assistants more sophisticated. \n",
    "Despite these advancements, ethical concerns such as bias in AI models and data privacy remain major challenges. \n",
    "As AI continues to evolve, researchers and policymakers must work together to ensure its responsible development and deployment.\n",
    "\"\"\"\n",
    "\n",
    "# Experiment with different parameters\n",
    "summary = summarize_text(long_text, temperature=0.5, max_tokens=50, top_p=0.8, frequency_penalty=0.2, presence_penalty=0.3)\n",
    "print(\"Summary:\\n\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Develop a tool that translates text from one language to another using the API.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Text: Hola, ¿cómo estás?\n"
     ]
    }
   ],
   "source": [
    "def translate_text(text, source_lang=\"English\", target_lang=\"French\", temperature=0.3, max_tokens=100, \n",
    "                   top_p=1.0, frequency_penalty=0.0, presence_penalty=0.0, logit_bias=None):\n",
    "    \"\"\"\n",
    "    Translates text from one language to another using OpenAI's GPT API.\n",
    "    \"\"\"\n",
    "\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI that translates text accurately.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Translate the following text from {source_lang} to {target_lang}:\\n\\n{text}\"}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "        logit_bias=logit_bias  # Optional, use None if not needed\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Example translation\n",
    "input_text = \"Hello, how are you?\"\n",
    "translated_text = translate_text(input_text, source_lang=\"English\", target_lang=\"Spanish\", temperature=0.5, max_tokens=50)\n",
    "print(\"Translated Text:\", translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool that determines the sentiment of a given text (positive, negative, neutral).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I absolutely love this product! It's amazing and works perfectly.\n",
      "Sentiment: Positive\n",
      "\n",
      "Text: This is the worst experience I've ever had. Terrible service.\n",
      "Sentiment: Negative\n",
      "\n",
      "Text: The item arrived on time. It works as expected, nothing special.\n",
      "Sentiment: Neutral\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def analyze_sentiment(text, temperature=0.0, max_tokens=5, top_p=1.0, \n",
    "                      frequency_penalty=0.0, presence_penalty=0.0, n=1, logprobs=None):\n",
    "    \"\"\"\n",
    "    Determines the sentiment (Positive, Negative, Neutral) of the given text.\n",
    "    \"\"\"\n",
    "\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI that classifies text sentiment as Positive, Negative, or Neutral.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Classify the sentiment of this text as 'Positive', 'Negative', or 'Neutral' only:\\n\\n{text}\"}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "        n=n,  # Number of responses\n",
    "        logprobs=logprobs  # Optional for probability analysis\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Example input texts for sentiment analysis\n",
    "texts = [\n",
    "    \"I absolutely love this product! It's amazing and works perfectly.\",\n",
    "    \"This is the worst experience I've ever had. Terrible service.\",\n",
    "    \"The item arrived on time. It works as expected, nothing special.\"\n",
    "]\n",
    "\n",
    "# Run sentiment analysis\n",
    "for text in texts:\n",
    "    sentiment = analyze_sentiment(text, temperature=0.0, max_tokens=5, top_p=0.9)\n",
    "    print(f\"Text: {text}\\nSentiment: {sentiment}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Create a text completion application that generates text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Once upon a time in a distant kingdom,\n",
      "Generated Text: there was a small village nestled at the edge of an ancient, enchanted forest. The villagers lived simple lives, farming the fertile land and tending to their animals. Yet, they all knew that the forest held secrets and magic that were beyond their understanding.\n",
      "\n",
      "Prompt: The future of artificial intelligence is\n",
      "Generated Text: a topic of much debate and speculation, with numerous possibilities and potential impacts on society. Here are some key areas where artificial intelligence is expected to evolve and influence the future:\n",
      "\n",
      "Prompt: A conversation between a detective and a suspect:\n",
      "Generated Text: **Detective:** Good afternoon, Mr. Johnson. Thank you for coming in. We just have a few questions regarding the events of last Friday night.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_text(prompt, temperature=0.7, max_tokens=100, top_p=1.0, \n",
    "                  frequency_penalty=0.0, presence_penalty=0.0, stop=None):\n",
    "    \"\"\"\n",
    "    Generates text based on an initial prompt using the OpenAI chat API.\n",
    "\n",
    "    Parameters:\n",
    "    - prompt (str): The input text to start the completion.\n",
    "    - temperature (float): Controls randomness (0.0 = deterministic, 1.0 = highly random).\n",
    "    - max_tokens (int): Limits response length.\n",
    "    - top_p (float): Controls diversity (lower values make output more focused).\n",
    "    - frequency_penalty (float): Discourages repeated phrases.\n",
    "    - presence_penalty (float): Encourages introducing new words.\n",
    "    - stop (list or str, optional): Stops generation when a specified sequence is reached.\n",
    "\n",
    "    Returns:\n",
    "    - str: The generated text.\n",
    "    \"\"\"\n",
    "\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI that continues text.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "        stop=stop  # Stop sequences\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Example prompts\n",
    "prompts = [\n",
    "    \"Once upon a time in a distant kingdom,\",\n",
    "    \"The future of artificial intelligence is\",\n",
    "    \"A conversation between a detective and a suspect:\"\n",
    "]\n",
    "\n",
    "# Run text completion for each prompt\n",
    "for prompt in prompts:\n",
    "    completion = generate_text(prompt, temperature=0.7, max_tokens=50, stop=[\"\\n\"])\n",
    "    print(f\"Prompt: {prompt}\\nGenerated Text: {completion}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS: Google Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a basic chatbot using Google Vertex AI to answer questions about a given topic.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Develop a script that summarizes long text inputs using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Create a tool that translates text from one language to another using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool using Google Vertex AI to determine the sentiment of a given text.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Develop a text completion application using Google Vertex AI to generate text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
